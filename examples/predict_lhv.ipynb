{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trained-creature",
   "metadata": {},
   "source": [
    "First, let's import everything we need, and load some lower heating value data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alternative-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Graph Operator - handles data preparation, model creation/recall, hand-off of data to model\n",
    "from graphchem import GraphOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "helpful-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other dependencies are for data segmentation, set metric calculations, plotting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "union-drilling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[C-]#[O+]', 'CO', 'C#C'] \n",
      " [[10.0], [21.0], [48.0]]\n"
     ]
    }
   ],
   "source": [
    "# Load some lower heating value data\n",
    "from graphchem.datasets import load_lhv\n",
    "smiles, lhv = load_lhv()\n",
    "print(smiles[:3], '\\n', lhv[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-admission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 310 78 78\n"
     ]
    }
   ],
   "source": [
    "# Create training, testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    smiles, lhv, test_size=0.20, random_state=42\n",
    ")\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-diversity",
   "metadata": {},
   "source": [
    "We need to set up some variables for our training process (i.e. hyper-parameters). In the future, these will be tunable to reduce model error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mobile-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    'task': 'graph',\n",
    "    'valid_size': 0.2,\n",
    "    'valid_epoch_iter': 1,\n",
    "    'valid_patience': 48,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.002,\n",
    "    'lr_decay': 0.0000001,\n",
    "    'epochs': 500,\n",
    "    'verbose': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-frank",
   "metadata": {},
   "source": [
    "We also need to define our model's architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "precise-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'n_messages': 2,\n",
    "    'n_hidden': 3,\n",
    "    'hidden_msg_dim': 128,\n",
    "    'hidden_dim': 256,\n",
    "    'dropout': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-spider",
   "metadata": {},
   "source": [
    "Now let's initialize the Graph Operator, and train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "matched-incentive",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjkessler/anaconda3/envs/torch_geometric/lib/python3.8/site-packages/graphchem-1.0.0-py3.8.egg/graphchem/operator.py:43: UserWarning: device config value not found: default value set, cpu\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 1491.8689821304813 | Valid Loss: 280.7094421386719\n",
      "Epoch: 1 | Train Loss: 280.7357856996598 | Valid Loss: 280.7094421386719\n",
      "Epoch: 2 | Train Loss: 177.5041016609438 | Valid Loss: 129.57264709472656\n",
      "Epoch: 3 | Train Loss: 151.56168193201864 | Valid Loss: 126.09510803222656\n",
      "Epoch: 4 | Train Loss: 143.44784152123236 | Valid Loss: 126.09510803222656\n",
      "Epoch: 5 | Train Loss: 142.00066375732422 | Valid Loss: 110.46143341064453\n",
      "Epoch: 6 | Train Loss: 121.44795768491683 | Valid Loss: 88.52388000488281\n",
      "Epoch: 7 | Train Loss: 98.49766909691596 | Valid Loss: 75.29000854492188\n",
      "Epoch: 8 | Train Loss: 85.2246327554026 | Valid Loss: 75.29000854492188\n",
      "Epoch: 9 | Train Loss: 83.31397345758253 | Valid Loss: 75.29000854492188\n",
      "Epoch: 10 | Train Loss: 110.49840397988596 | Valid Loss: 75.29000854492188\n",
      "Epoch: 11 | Train Loss: 121.05464369250882 | Valid Loss: 74.58497619628906\n",
      "Epoch: 12 | Train Loss: 103.07007623487904 | Valid Loss: 74.58497619628906\n",
      "Epoch: 13 | Train Loss: 90.55709297426286 | Valid Loss: 74.58497619628906\n",
      "Epoch: 14 | Train Loss: 84.96976507863691 | Valid Loss: 74.58497619628906\n",
      "Epoch: 15 | Train Loss: 77.22592704526839 | Valid Loss: 74.58497619628906\n",
      "Epoch: 16 | Train Loss: 67.94492979972593 | Valid Loss: 59.55061721801758\n",
      "Epoch: 17 | Train Loss: 49.08867411459646 | Valid Loss: 59.55061721801758\n",
      "Epoch: 18 | Train Loss: 43.88493900914346 | Valid Loss: 59.55061721801758\n",
      "Epoch: 19 | Train Loss: 36.66211977312642 | Valid Loss: 59.55061721801758\n",
      "Epoch: 20 | Train Loss: 43.037482107839274 | Valid Loss: 47.45825958251953\n",
      "Epoch: 21 | Train Loss: 37.06476728377804 | Valid Loss: 47.45825958251953\n",
      "Epoch: 22 | Train Loss: 60.5398799527076 | Valid Loss: 47.45825958251953\n",
      "Epoch: 23 | Train Loss: 58.375479421307965 | Valid Loss: 47.45825958251953\n",
      "Epoch: 24 | Train Loss: 47.81224121585969 | Valid Loss: 47.45825958251953\n",
      "Epoch: 25 | Train Loss: 41.306087740005985 | Valid Loss: 47.45825958251953\n",
      "Epoch: 26 | Train Loss: 45.071647182587654 | Valid Loss: 47.45825958251953\n",
      "Epoch: 27 | Train Loss: 53.32234511836882 | Valid Loss: 47.45825958251953\n",
      "Epoch: 28 | Train Loss: 74.22771896854523 | Valid Loss: 47.45825958251953\n",
      "Epoch: 29 | Train Loss: 61.92119549166772 | Valid Loss: 47.45825958251953\n",
      "Epoch: 30 | Train Loss: 45.45734190171765 | Valid Loss: 47.45825958251953\n",
      "Epoch: 31 | Train Loss: 41.16074629752867 | Valid Loss: 47.45825958251953\n",
      "Epoch: 32 | Train Loss: 33.83358432400611 | Valid Loss: 47.45825958251953\n",
      "Epoch: 33 | Train Loss: 28.182119923253214 | Valid Loss: 47.268043518066406\n",
      "Epoch: 34 | Train Loss: 32.39440425749748 | Valid Loss: 47.268043518066406\n",
      "Epoch: 35 | Train Loss: 51.626241499377834 | Valid Loss: 47.268043518066406\n",
      "Epoch: 36 | Train Loss: 39.58899737942603 | Valid Loss: 43.35643005371094\n",
      "Epoch: 37 | Train Loss: 27.128757692152455 | Valid Loss: 43.35643005371094\n",
      "Epoch: 38 | Train Loss: 23.703163639191658 | Valid Loss: 37.02687454223633\n",
      "Epoch: 39 | Train Loss: 25.309888778194303 | Valid Loss: 37.02687454223633\n",
      "Epoch: 40 | Train Loss: 28.715543193201864 | Valid Loss: 37.02687454223633\n",
      "Epoch: 41 | Train Loss: 25.84743776629048 | Valid Loss: 37.02687454223633\n",
      "Epoch: 42 | Train Loss: 26.180180026638894 | Valid Loss: 37.02687454223633\n",
      "Epoch: 43 | Train Loss: 28.247926712036133 | Valid Loss: 37.02687454223633\n",
      "Epoch: 44 | Train Loss: 20.623784403647146 | Valid Loss: 37.02687454223633\n",
      "Epoch: 45 | Train Loss: 24.42538796701739 | Valid Loss: 37.02687454223633\n",
      "Epoch: 46 | Train Loss: 23.71467178098617 | Valid Loss: 37.02687454223633\n",
      "Epoch: 47 | Train Loss: 25.51742313754174 | Valid Loss: 37.02687454223633\n",
      "Epoch: 48 | Train Loss: 23.164479409494707 | Valid Loss: 37.02687454223633\n",
      "Epoch: 49 | Train Loss: 21.692345526910596 | Valid Loss: 37.02687454223633\n",
      "Epoch: 50 | Train Loss: 29.958832710020005 | Valid Loss: 37.02687454223633\n",
      "Epoch: 51 | Train Loss: 29.064709140408425 | Valid Loss: 37.02687454223633\n",
      "Epoch: 52 | Train Loss: 22.77043797892909 | Valid Loss: 37.02687454223633\n",
      "Epoch: 53 | Train Loss: 18.63718149738927 | Valid Loss: 37.02687454223633\n",
      "Epoch: 54 | Train Loss: 18.214032234684115 | Valid Loss: 37.02687454223633\n",
      "Epoch: 55 | Train Loss: 20.6151861375378 | Valid Loss: 37.02687454223633\n",
      "Epoch: 56 | Train Loss: 19.650502789405085 | Valid Loss: 37.02687454223633\n",
      "Epoch: 57 | Train Loss: 23.10248479535503 | Valid Loss: 37.02687454223633\n",
      "Epoch: 58 | Train Loss: 17.928839806587465 | Valid Loss: 37.02687454223633\n",
      "Epoch: 59 | Train Loss: 20.914376658778036 | Valid Loss: 37.02687454223633\n",
      "Epoch: 60 | Train Loss: 22.61641293187295 | Valid Loss: 34.11890411376953\n",
      "Epoch: 61 | Train Loss: 20.725019885647683 | Valid Loss: 34.11890411376953\n",
      "Epoch: 62 | Train Loss: 23.305852643905148 | Valid Loss: 34.11890411376953\n",
      "Epoch: 63 | Train Loss: 18.335139859107233 | Valid Loss: 34.11890411376953\n",
      "Epoch: 64 | Train Loss: 16.85756907924529 | Valid Loss: 34.11890411376953\n",
      "Epoch: 65 | Train Loss: 15.167970442002819 | Valid Loss: 34.11890411376953\n",
      "Epoch: 66 | Train Loss: 13.317276954650879 | Valid Loss: 34.11890411376953\n",
      "Epoch: 67 | Train Loss: 11.319944658587056 | Valid Loss: 33.17915344238281\n",
      "Epoch: 68 | Train Loss: 11.603667597616873 | Valid Loss: 31.055456161499023\n",
      "Epoch: 69 | Train Loss: 11.93169778393161 | Valid Loss: 31.055456161499023\n",
      "Epoch: 70 | Train Loss: 11.378797623418993 | Valid Loss: 31.055456161499023\n",
      "Epoch: 71 | Train Loss: 10.830127962173954 | Valid Loss: 31.055456161499023\n",
      "Epoch: 72 | Train Loss: 10.70073749173072 | Valid Loss: 31.055456161499023\n",
      "Epoch: 73 | Train Loss: 11.21658423639113 | Valid Loss: 31.055456161499023\n",
      "Epoch: 74 | Train Loss: 11.255727368016396 | Valid Loss: 31.055456161499023\n",
      "Epoch: 75 | Train Loss: 11.284028945430633 | Valid Loss: 31.055456161499023\n",
      "Epoch: 76 | Train Loss: 13.469046500421339 | Valid Loss: 31.055456161499023\n",
      "Epoch: 77 | Train Loss: 15.261460058150753 | Valid Loss: 31.055456161499023\n",
      "Epoch: 78 | Train Loss: 16.516515424174646 | Valid Loss: 31.055456161499023\n",
      "Epoch: 79 | Train Loss: 14.462196780789283 | Valid Loss: 31.055456161499023\n",
      "Epoch: 80 | Train Loss: 16.92206504268031 | Valid Loss: 31.055456161499023\n",
      "Epoch: 81 | Train Loss: 15.430086043573194 | Valid Loss: 31.055456161499023\n",
      "Epoch: 82 | Train Loss: 14.744831638951455 | Valid Loss: 31.055456161499023\n",
      "Epoch: 83 | Train Loss: 13.584636965105611 | Valid Loss: 31.055456161499023\n",
      "Epoch: 84 | Train Loss: 14.34932234979445 | Valid Loss: 29.129335403442383\n",
      "Epoch: 85 | Train Loss: 13.135831309903052 | Valid Loss: 29.129335403442383\n",
      "Epoch: 86 | Train Loss: 22.566340400326638 | Valid Loss: 29.129335403442383\n",
      "Epoch: 87 | Train Loss: 15.160139514553931 | Valid Loss: 29.129335403442383\n",
      "Epoch: 88 | Train Loss: 10.723241775266585 | Valid Loss: 28.687707901000977\n",
      "Epoch: 89 | Train Loss: 9.8072937380883 | Valid Loss: 28.124862670898438\n",
      "Epoch: 90 | Train Loss: 9.622544903909006 | Valid Loss: 28.124862670898438\n",
      "Epoch: 91 | Train Loss: 11.124491876171481 | Valid Loss: 24.20061683654785\n",
      "Epoch: 92 | Train Loss: 9.141207018206197 | Valid Loss: 24.20061683654785\n",
      "Epoch: 93 | Train Loss: 6.886459012185374 | Valid Loss: 24.20061683654785\n",
      "Epoch: 94 | Train Loss: 7.1510120361082015 | Valid Loss: 24.20061683654785\n",
      "Epoch: 95 | Train Loss: 7.590349720370385 | Valid Loss: 24.20061683654785\n",
      "Epoch: 96 | Train Loss: 8.509622635379914 | Valid Loss: 24.20061683654785\n",
      "Epoch: 97 | Train Loss: 6.688483653529998 | Valid Loss: 24.20061683654785\n",
      "Epoch: 98 | Train Loss: 6.700057891107375 | Valid Loss: 24.20061683654785\n",
      "Epoch: 99 | Train Loss: 6.300966324344758 | Valid Loss: 24.20061683654785\n",
      "Epoch: 100 | Train Loss: 6.857585399381576 | Valid Loss: 23.117708206176758\n",
      "Epoch: 101 | Train Loss: 8.05003821465277 | Valid Loss: 23.117708206176758\n",
      "Epoch: 102 | Train Loss: 7.558410167694092 | Valid Loss: 23.117708206176758\n",
      "Epoch: 103 | Train Loss: 7.068626642227173 | Valid Loss: 23.117708206176758\n",
      "Epoch: 104 | Train Loss: 7.830874319999449 | Valid Loss: 23.117708206176758\n",
      "Epoch: 105 | Train Loss: 7.232220680482926 | Valid Loss: 23.117708206176758\n",
      "Epoch: 106 | Train Loss: 7.350782655900525 | Valid Loss: 22.026145935058594\n",
      "Epoch: 107 | Train Loss: 6.659341719842726 | Valid Loss: 22.026145935058594\n",
      "Epoch: 108 | Train Loss: 5.761818547402659 | Valid Loss: 22.026145935058594\n",
      "Epoch: 109 | Train Loss: 5.804549955552624 | Valid Loss: 22.026145935058594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110 | Train Loss: 5.4599123154917075 | Valid Loss: 22.026145935058594\n",
      "Epoch: 111 | Train Loss: 6.089518823931294 | Valid Loss: 22.026145935058594\n",
      "Epoch: 112 | Train Loss: 5.52515975890621 | Valid Loss: 22.026145935058594\n",
      "Epoch: 113 | Train Loss: 5.422321319580078 | Valid Loss: 22.026145935058594\n",
      "Epoch: 114 | Train Loss: 5.345855405253749 | Valid Loss: 22.026145935058594\n",
      "Epoch: 115 | Train Loss: 5.593592505301198 | Valid Loss: 22.026145935058594\n",
      "Epoch: 116 | Train Loss: 6.871968238584457 | Valid Loss: 22.026145935058594\n",
      "Epoch: 117 | Train Loss: 3.997867415028234 | Valid Loss: 22.026145935058594\n",
      "Epoch: 118 | Train Loss: 4.485982433442147 | Valid Loss: 21.064115524291992\n",
      "Epoch: 119 | Train Loss: 4.427071279095065 | Valid Loss: 21.064115524291992\n",
      "Epoch: 120 | Train Loss: 6.20421520356209 | Valid Loss: 19.75558853149414\n",
      "Epoch: 121 | Train Loss: 4.526533488304384 | Valid Loss: 19.75558853149414\n",
      "Epoch: 122 | Train Loss: 4.355928344111288 | Valid Loss: 19.75558853149414\n",
      "Epoch: 123 | Train Loss: 3.8177903467609036 | Valid Loss: 19.75558853149414\n",
      "Epoch: 124 | Train Loss: 3.5058345640859296 | Valid Loss: 19.75558853149414\n",
      "Epoch: 125 | Train Loss: 4.64782533337993 | Valid Loss: 19.75558853149414\n",
      "Epoch: 126 | Train Loss: 5.3939026863344255 | Valid Loss: 19.75558853149414\n",
      "Epoch: 127 | Train Loss: 4.481238295955043 | Valid Loss: 17.630651473999023\n",
      "Epoch: 128 | Train Loss: 4.505478228292158 | Valid Loss: 17.630651473999023\n",
      "Epoch: 129 | Train Loss: 3.558847996496385 | Valid Loss: 17.630651473999023\n",
      "Epoch: 130 | Train Loss: 3.6115905777100594 | Valid Loss: 16.761266708374023\n",
      "Epoch: 131 | Train Loss: 3.400163642821773 | Valid Loss: 16.761266708374023\n",
      "Epoch: 132 | Train Loss: 4.3020910447643645 | Valid Loss: 16.761266708374023\n",
      "Epoch: 133 | Train Loss: 4.132815437932169 | Valid Loss: 16.435466766357422\n",
      "Epoch: 134 | Train Loss: 3.7273799603985203 | Valid Loss: 16.435466766357422\n",
      "Epoch: 135 | Train Loss: 3.760442033890755 | Valid Loss: 16.435466766357422\n",
      "Epoch: 136 | Train Loss: 4.040977201154155 | Valid Loss: 16.435466766357422\n",
      "Epoch: 137 | Train Loss: 3.706589129663283 | Valid Loss: 16.435466766357422\n",
      "Epoch: 138 | Train Loss: 4.400371136203889 | Valid Loss: 16.435466766357422\n",
      "Epoch: 139 | Train Loss: 5.197767519181775 | Valid Loss: 16.435466766357422\n",
      "Epoch: 140 | Train Loss: 4.599897907626245 | Valid Loss: 16.435466766357422\n",
      "Epoch: 141 | Train Loss: 3.3229596537928425 | Valid Loss: 16.435466766357422\n",
      "Epoch: 142 | Train Loss: 2.6711191592677945 | Valid Loss: 16.435466766357422\n",
      "Epoch: 143 | Train Loss: 2.4674276844147713 | Valid Loss: 16.435466766357422\n",
      "Epoch: 144 | Train Loss: 3.814824319654895 | Valid Loss: 16.435466766357422\n",
      "Epoch: 145 | Train Loss: 2.926060268955846 | Valid Loss: 16.435466766357422\n",
      "Epoch: 146 | Train Loss: 3.0518712843618085 | Valid Loss: 16.435466766357422\n",
      "Epoch: 147 | Train Loss: 3.454996109008789 | Valid Loss: 16.435466766357422\n",
      "Epoch: 148 | Train Loss: 4.069792178369338 | Valid Loss: 16.435466766357422\n",
      "Epoch: 149 | Train Loss: 4.605910608845372 | Valid Loss: 15.707915306091309\n",
      "Epoch: 150 | Train Loss: 4.44201539408776 | Valid Loss: 15.707915306091309\n",
      "Epoch: 151 | Train Loss: 3.6021481406304146 | Valid Loss: 15.707915306091309\n",
      "Epoch: 152 | Train Loss: 2.2465598083311513 | Valid Loss: 15.707915306091309\n",
      "Epoch: 153 | Train Loss: 2.0262794802265782 | Valid Loss: 15.707915306091309\n",
      "Epoch: 154 | Train Loss: 1.889890355448569 | Valid Loss: 15.707915306091309\n",
      "Epoch: 155 | Train Loss: 2.136482346442438 | Valid Loss: 15.707915306091309\n",
      "Epoch: 156 | Train Loss: 2.0962910421432985 | Valid Loss: 15.41165542602539\n",
      "Epoch: 157 | Train Loss: 2.3554406704441195 | Valid Loss: 15.41165542602539\n",
      "Epoch: 158 | Train Loss: 2.271958085798448 | Valid Loss: 15.41165542602539\n",
      "Epoch: 159 | Train Loss: 1.856622576713562 | Valid Loss: 15.41165542602539\n",
      "Epoch: 160 | Train Loss: 2.4738129954184256 | Valid Loss: 15.41165542602539\n",
      "Epoch: 161 | Train Loss: 3.4477202046302056 | Valid Loss: 15.41165542602539\n",
      "Epoch: 162 | Train Loss: 2.980527062569895 | Valid Loss: 15.41165542602539\n",
      "Epoch: 163 | Train Loss: 2.7209843204867457 | Valid Loss: 15.41165542602539\n",
      "Epoch: 164 | Train Loss: 2.917799572790823 | Valid Loss: 15.41165542602539\n",
      "Epoch: 165 | Train Loss: 3.4504024943997784 | Valid Loss: 15.41165542602539\n",
      "Epoch: 166 | Train Loss: 2.8560691956550843 | Valid Loss: 15.41165542602539\n",
      "Epoch: 167 | Train Loss: 2.7954690302571943 | Valid Loss: 14.399646759033203\n",
      "Epoch: 168 | Train Loss: 2.5053752237750637 | Valid Loss: 14.399646759033203\n",
      "Epoch: 169 | Train Loss: 3.1259721556017475 | Valid Loss: 14.399646759033203\n",
      "Epoch: 170 | Train Loss: 2.7300027108961538 | Valid Loss: 14.399646759033203\n",
      "Epoch: 171 | Train Loss: 2.2477891522069133 | Valid Loss: 14.399646759033203\n",
      "Epoch: 172 | Train Loss: 2.607609598867355 | Valid Loss: 14.399646759033203\n",
      "Epoch: 173 | Train Loss: 2.6846954822540283 | Valid Loss: 14.399646759033203\n",
      "Epoch: 174 | Train Loss: 2.6079955562468498 | Valid Loss: 14.399646759033203\n",
      "Epoch: 175 | Train Loss: 2.5332529544830322 | Valid Loss: 14.399646759033203\n",
      "Epoch: 176 | Train Loss: 3.405206887952743 | Valid Loss: 14.399646759033203\n",
      "Epoch: 177 | Train Loss: 2.9157175094850603 | Valid Loss: 14.399646759033203\n",
      "Epoch: 178 | Train Loss: 2.8617620814231133 | Valid Loss: 14.399646759033203\n",
      "Epoch: 179 | Train Loss: 2.7276656935291905 | Valid Loss: 14.399646759033203\n",
      "Epoch: 180 | Train Loss: 2.652877523053077 | Valid Loss: 14.399646759033203\n",
      "Epoch: 181 | Train Loss: 4.074003342659243 | Valid Loss: 14.399646759033203\n",
      "Epoch: 182 | Train Loss: 2.9334841235991447 | Valid Loss: 14.399646759033203\n",
      "Epoch: 183 | Train Loss: 2.893432224950483 | Valid Loss: 14.399646759033203\n",
      "Epoch: 184 | Train Loss: 2.75720953172253 | Valid Loss: 14.399646759033203\n",
      "Epoch: 185 | Train Loss: 2.3650003979282994 | Valid Loss: 14.399646759033203\n",
      "Epoch: 186 | Train Loss: 2.342104750294839 | Valid Loss: 14.399646759033203\n",
      "Epoch: 187 | Train Loss: 2.21382491050228 | Valid Loss: 14.399646759033203\n",
      "Epoch: 188 | Train Loss: 1.7460874742077244 | Valid Loss: 14.399646759033203\n",
      "Epoch: 189 | Train Loss: 2.131474587225145 | Valid Loss: 14.399646759033203\n",
      "Epoch: 190 | Train Loss: 2.412101476423202 | Valid Loss: 14.399646759033203\n",
      "Epoch: 191 | Train Loss: 2.02581391795989 | Valid Loss: 13.494115829467773\n",
      "Epoch: 192 | Train Loss: 2.1742991785849295 | Valid Loss: 13.347604751586914\n",
      "Epoch: 193 | Train Loss: 1.9658098220825195 | Valid Loss: 13.347604751586914\n",
      "Epoch: 194 | Train Loss: 1.8349669979464622 | Valid Loss: 13.347604751586914\n",
      "Epoch: 195 | Train Loss: 2.515265272509667 | Valid Loss: 13.347604751586914\n",
      "Epoch: 196 | Train Loss: 2.4054874950839626 | Valid Loss: 13.347604751586914\n",
      "Epoch: 197 | Train Loss: 2.342380485227031 | Valid Loss: 13.347604751586914\n",
      "Epoch: 198 | Train Loss: 1.8573688691662205 | Valid Loss: 13.347604751586914\n",
      "Epoch: 199 | Train Loss: 1.5984599513392295 | Valid Loss: 13.347604751586914\n",
      "Epoch: 200 | Train Loss: 1.9511103860793575 | Valid Loss: 13.347604751586914\n",
      "Epoch: 201 | Train Loss: 2.1107316478606193 | Valid Loss: 13.347604751586914\n",
      "Epoch: 202 | Train Loss: 1.880095105017385 | Valid Loss: 13.347604751586914\n",
      "Epoch: 203 | Train Loss: 1.7173303557980446 | Valid Loss: 13.221833229064941\n",
      "Epoch: 204 | Train Loss: 1.7030036910887687 | Valid Loss: 13.221833229064941\n",
      "Epoch: 205 | Train Loss: 1.7658171115383026 | Valid Loss: 13.221833229064941\n",
      "Epoch: 206 | Train Loss: 1.3533439828503517 | Valid Loss: 13.221833229064941\n",
      "Epoch: 207 | Train Loss: 1.6828538640852897 | Valid Loss: 13.221833229064941\n",
      "Epoch: 208 | Train Loss: 1.5872148083102318 | Valid Loss: 13.221833229064941\n",
      "Epoch: 209 | Train Loss: 1.837728742630251 | Valid Loss: 13.221833229064941\n",
      "Epoch: 210 | Train Loss: 1.548996175489118 | Valid Loss: 13.221833229064941\n",
      "Epoch: 211 | Train Loss: 1.851555908879926 | Valid Loss: 13.221833229064941\n",
      "Epoch: 212 | Train Loss: 1.8873140658101728 | Valid Loss: 13.221833229064941\n",
      "Epoch: 213 | Train Loss: 1.7237607048403831 | Valid Loss: 13.221833229064941\n",
      "Epoch: 214 | Train Loss: 1.6220620216861847 | Valid Loss: 13.221833229064941\n",
      "Epoch: 215 | Train Loss: 1.6962028241926623 | Valid Loss: 13.221833229064941\n",
      "Epoch: 216 | Train Loss: 1.8044004440307617 | Valid Loss: 11.734382629394531\n",
      "Epoch: 217 | Train Loss: 2.0138392025424587 | Valid Loss: 11.700850486755371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 218 | Train Loss: 1.5186438983486545 | Valid Loss: 10.445535659790039\n",
      "Epoch: 219 | Train Loss: 1.6297202302563576 | Valid Loss: 10.445535659790039\n",
      "Epoch: 220 | Train Loss: 1.702839978279606 | Valid Loss: 10.445535659790039\n",
      "Epoch: 221 | Train Loss: 1.7411507560360817 | Valid Loss: 10.445535659790039\n",
      "Epoch: 222 | Train Loss: 1.9471208126314226 | Valid Loss: 10.445535659790039\n",
      "Epoch: 223 | Train Loss: 1.8951215974746212 | Valid Loss: 10.445535659790039\n",
      "Epoch: 224 | Train Loss: 2.20454046803136 | Valid Loss: 10.445535659790039\n",
      "Epoch: 225 | Train Loss: 2.0459997423233522 | Valid Loss: 10.445535659790039\n",
      "Epoch: 226 | Train Loss: 1.5765603588473411 | Valid Loss: 10.445535659790039\n",
      "Epoch: 227 | Train Loss: 2.247507825974495 | Valid Loss: 10.445535659790039\n",
      "Epoch: 228 | Train Loss: 1.630893426556741 | Valid Loss: 10.445535659790039\n",
      "Epoch: 229 | Train Loss: 1.58402681350708 | Valid Loss: 10.445535659790039\n",
      "Epoch: 230 | Train Loss: 1.8447369067899642 | Valid Loss: 10.445535659790039\n",
      "Epoch: 231 | Train Loss: 1.6641884888372114 | Valid Loss: 10.445535659790039\n",
      "Epoch: 232 | Train Loss: 2.2026933181670403 | Valid Loss: 10.445535659790039\n",
      "Epoch: 233 | Train Loss: 2.335072228985448 | Valid Loss: 10.445535659790039\n",
      "Epoch: 234 | Train Loss: 2.484691858291626 | Valid Loss: 10.445535659790039\n",
      "Epoch: 235 | Train Loss: 2.1964005039584253 | Valid Loss: 10.445535659790039\n",
      "Epoch: 236 | Train Loss: 2.0224743889224146 | Valid Loss: 10.445535659790039\n",
      "Epoch: 237 | Train Loss: 2.2235798758845173 | Valid Loss: 10.445535659790039\n",
      "Epoch: 238 | Train Loss: 2.2178243206393335 | Valid Loss: 10.445535659790039\n",
      "Epoch: 239 | Train Loss: 2.442896273828322 | Valid Loss: 10.445535659790039\n",
      "Epoch: 240 | Train Loss: 2.2411122591264787 | Valid Loss: 10.445535659790039\n",
      "Epoch: 241 | Train Loss: 2.1107707292802873 | Valid Loss: 10.445535659790039\n",
      "Epoch: 242 | Train Loss: 2.236237202921221 | Valid Loss: 10.445535659790039\n",
      "Epoch: 243 | Train Loss: 2.1536897613156225 | Valid Loss: 10.445535659790039\n",
      "Epoch: 244 | Train Loss: 2.0998892861027874 | Valid Loss: 10.445535659790039\n",
      "Epoch: 245 | Train Loss: 2.631803189554522 | Valid Loss: 10.445535659790039\n",
      "Epoch: 246 | Train Loss: 2.294521716333205 | Valid Loss: 10.445535659790039\n",
      "Epoch: 247 | Train Loss: 2.2540539464642926 | Valid Loss: 10.445535659790039\n",
      "Epoch: 248 | Train Loss: 2.7038441608029027 | Valid Loss: 10.445535659790039\n",
      "Epoch: 249 | Train Loss: 1.5242859240501159 | Valid Loss: 10.445535659790039\n",
      "Epoch: 250 | Train Loss: 1.6294212610490861 | Valid Loss: 10.445535659790039\n",
      "Epoch: 251 | Train Loss: 2.164760366562874 | Valid Loss: 10.445535659790039\n",
      "Epoch: 252 | Train Loss: 1.8155637325779084 | Valid Loss: 10.445535659790039\n",
      "Epoch: 253 | Train Loss: 1.8371491970554474 | Valid Loss: 10.445535659790039\n",
      "Epoch: 254 | Train Loss: 1.4625336470142487 | Valid Loss: 10.445535659790039\n",
      "Epoch: 255 | Train Loss: 1.6533734279294168 | Valid Loss: 10.445535659790039\n",
      "Epoch: 256 | Train Loss: 1.8399835248147287 | Valid Loss: 10.445535659790039\n",
      "Epoch: 257 | Train Loss: 1.892310057916949 | Valid Loss: 10.445535659790039\n",
      "Epoch: 258 | Train Loss: 2.1653127824106524 | Valid Loss: 10.445535659790039\n",
      "Epoch: 259 | Train Loss: 2.74190701207807 | Valid Loss: 10.445535659790039\n",
      "Epoch: 260 | Train Loss: 2.148268738100606 | Valid Loss: 10.445535659790039\n",
      "Epoch: 261 | Train Loss: 2.944482757199195 | Valid Loss: 10.445535659790039\n",
      "Epoch: 262 | Train Loss: 2.1308600518011276 | Valid Loss: 10.445535659790039\n",
      "Epoch: 263 | Train Loss: 2.0793915410195627 | Valid Loss: 10.445535659790039\n",
      "Epoch: 264 | Train Loss: 2.4572506873838362 | Valid Loss: 10.445535659790039\n",
      "Epoch: 265 | Train Loss: 2.6418682067624983 | Valid Loss: 10.445535659790039\n",
      "Epoch: 266 | Train Loss: 2.2233263830984793 | Valid Loss: 10.445535659790039\n"
     ]
    }
   ],
   "source": [
    "go = GraphOperator(config=training_config)\n",
    "go.train(X_train, y_train, model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-malawi",
   "metadata": {},
   "source": [
    "Let's get predictions, then calculate prediction errors for the training and testing subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extended-charlotte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set: R2 = 0.7913214719874528, MAE = 1.7062225341796875\n",
      "Train Set: R2 = 0.9481418084360903, MAE = 0.9346351623535156\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = go.use(X_train)\n",
    "y_test_pred = go.use(X_test)\n",
    "\n",
    "mae_test = median_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "mae_train = median_absolute_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print('Test Set: R2 = {}, MAE = {}'.format(r2_test, mae_test))\n",
    "print('Train Set: R2 = {}, MAE = {}'.format(r2_train, mae_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-stomach",
   "metadata": {},
   "source": [
    "And let's plot our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "second-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Predicted Lower Heating Value vs. Experimental Lower Heating Value')\n",
    "plt.xlabel('Experimental Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.scatter(y_train, y_train_pred, color='blue', label='Train')\n",
    "plt.scatter(y_test, y_test_pred, color='red', label='Test')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-array",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
