{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trained-creature",
   "metadata": {},
   "source": [
    "First, let's import everything we need, and load some MON data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alternative-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Graph Operator - handles data preparation, model creation/recall, hand-off of data to model\n",
    "from graphchem import GraphOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "helpful-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other dependencies are for data segmentation, set metric calculations, plotting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "union-drilling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CCCCO', 'CCO', 'CO'] \n",
      " [[85.0], [90.0], [89.0]]\n"
     ]
    }
   ],
   "source": [
    "# Load some MON data\n",
    "from graphchem.datasets import load_mon\n",
    "smiles, mon = load_mon()\n",
    "print(smiles[:3], '\\n', mon[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "revolutionary-admission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246 246 62 62\n"
     ]
    }
   ],
   "source": [
    "# Create training, testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    smiles, mon, test_size=0.20, random_state=42\n",
    ")\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-diversity",
   "metadata": {},
   "source": [
    "We need to set up some variables for our training process (i.e. hyper-parameters). In the future, these will be tunable to reduce model error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mobile-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    'task': 'graph',\n",
    "    'valid_size': 0.2,\n",
    "    'valid_epoch_iter': 1,\n",
    "    'valid_patience': 64,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'lr_decay': 0.0000001,\n",
    "    'epochs': 500,\n",
    "    'verbose': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-frank",
   "metadata": {},
   "source": [
    "We also need to define our model's architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "precise-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'n_messages': 2,\n",
    "    'n_hidden': 3,\n",
    "    'hidden_msg_dim': 128,\n",
    "    'hidden_dim': 256,\n",
    "    'dropout': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-spider",
   "metadata": {},
   "source": [
    "Now let's initialize the Graph Operator, and train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "matched-incentive",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjkessler/anaconda3/envs/torch_geometric/lib/python3.8/site-packages/graphchem-1.0.0-py3.8.egg/graphchem/operator.py:43: UserWarning: device config value not found: default value set, cpu\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 2712.8634755660078 | Valid Loss: 1719.685302734375\n",
      "Epoch: 1 | Train Loss: 1044.531773158482 | Valid Loss: 650.1519775390625\n",
      "Epoch: 2 | Train Loss: 675.7366519850127 | Valid Loss: 521.6205444335938\n",
      "Epoch: 3 | Train Loss: 480.15634528958066 | Valid Loss: 521.6205444335938\n",
      "Epoch: 4 | Train Loss: 513.2172178930166 | Valid Loss: 386.8822021484375\n",
      "Epoch: 5 | Train Loss: 449.6928701595384 | Valid Loss: 386.8822021484375\n",
      "Epoch: 6 | Train Loss: 460.8499425771285 | Valid Loss: 386.8822021484375\n",
      "Epoch: 7 | Train Loss: 399.0389155173788 | Valid Loss: 386.8822021484375\n",
      "Epoch: 8 | Train Loss: 495.8991661850287 | Valid Loss: 379.1761779785156\n",
      "Epoch: 9 | Train Loss: 395.26361146265145 | Valid Loss: 353.39996337890625\n",
      "Epoch: 10 | Train Loss: 392.9388228435906 | Valid Loss: 353.39996337890625\n",
      "Epoch: 11 | Train Loss: 387.6839854960539 | Valid Loss: 350.36004638671875\n",
      "Epoch: 12 | Train Loss: 393.19954603545517 | Valid Loss: 350.36004638671875\n",
      "Epoch: 13 | Train Loss: 396.86236400993505 | Valid Loss: 344.5745849609375\n",
      "Epoch: 14 | Train Loss: 378.3821274115115 | Valid Loss: 344.5745849609375\n",
      "Epoch: 15 | Train Loss: 388.4575319874043 | Valid Loss: 344.5745849609375\n",
      "Epoch: 16 | Train Loss: 393.4202544543208 | Valid Loss: 344.5745849609375\n",
      "Epoch: 17 | Train Loss: 476.40614536830356 | Valid Loss: 344.5745849609375\n",
      "Epoch: 18 | Train Loss: 493.41508515027107 | Valid Loss: 344.5745849609375\n",
      "Epoch: 19 | Train Loss: 521.0097687390386 | Valid Loss: 344.5745849609375\n",
      "Epoch: 20 | Train Loss: 502.2940667600048 | Valid Loss: 344.5745849609375\n",
      "Epoch: 21 | Train Loss: 384.3027047137825 | Valid Loss: 344.5745849609375\n",
      "Epoch: 22 | Train Loss: 378.76418755978955 | Valid Loss: 344.5745849609375\n",
      "Epoch: 23 | Train Loss: 372.7278753786671 | Valid Loss: 344.5745849609375\n",
      "Epoch: 24 | Train Loss: 363.6860712790976 | Valid Loss: 328.0625915527344\n",
      "Epoch: 25 | Train Loss: 336.80126174615356 | Valid Loss: 314.8061218261719\n",
      "Epoch: 26 | Train Loss: 332.0996542171556 | Valid Loss: 303.6336669921875\n",
      "Epoch: 27 | Train Loss: 340.92993693449057 | Valid Loss: 284.6553649902344\n",
      "Epoch: 28 | Train Loss: 337.8724387032645 | Valid Loss: 284.6553649902344\n",
      "Epoch: 29 | Train Loss: 357.0566842215402 | Valid Loss: 284.6553649902344\n",
      "Epoch: 30 | Train Loss: 432.8504704845195 | Valid Loss: 284.6553649902344\n",
      "Epoch: 31 | Train Loss: 333.9854951196787 | Valid Loss: 284.6553649902344\n",
      "Epoch: 32 | Train Loss: 324.77693767936864 | Valid Loss: 284.6553649902344\n",
      "Epoch: 33 | Train Loss: 406.35033556879785 | Valid Loss: 284.6553649902344\n",
      "Epoch: 34 | Train Loss: 508.77813720703125 | Valid Loss: 284.6553649902344\n",
      "Epoch: 35 | Train Loss: 387.1835632324219 | Valid Loss: 284.6553649902344\n",
      "Epoch: 36 | Train Loss: 476.65442673040894 | Valid Loss: 284.6553649902344\n",
      "Epoch: 37 | Train Loss: 452.5776068239796 | Valid Loss: 284.6553649902344\n",
      "Epoch: 38 | Train Loss: 388.38832123425544 | Valid Loss: 284.6553649902344\n",
      "Epoch: 39 | Train Loss: 414.0475551060268 | Valid Loss: 284.6553649902344\n",
      "Epoch: 40 | Train Loss: 363.2644292091837 | Valid Loss: 284.6553649902344\n",
      "Epoch: 41 | Train Loss: 299.9244400335818 | Valid Loss: 284.6553649902344\n",
      "Epoch: 42 | Train Loss: 316.90358064612565 | Valid Loss: 282.2431640625\n",
      "Epoch: 43 | Train Loss: 305.4849816147162 | Valid Loss: 282.2431640625\n",
      "Epoch: 44 | Train Loss: 296.1573550165916 | Valid Loss: 282.2431640625\n",
      "Epoch: 45 | Train Loss: 312.1380403479751 | Valid Loss: 282.2431640625\n",
      "Epoch: 46 | Train Loss: 315.0297969895966 | Valid Loss: 282.2431640625\n",
      "Epoch: 47 | Train Loss: 289.4223621913365 | Valid Loss: 282.2431640625\n",
      "Epoch: 48 | Train Loss: 291.7433832908163 | Valid Loss: 282.2431640625\n",
      "Epoch: 49 | Train Loss: 357.6611066545759 | Valid Loss: 282.2431640625\n",
      "Epoch: 50 | Train Loss: 275.333504813058 | Valid Loss: 277.6435241699219\n",
      "Epoch: 51 | Train Loss: 291.5847977618782 | Valid Loss: 277.6435241699219\n",
      "Epoch: 52 | Train Loss: 307.61729649135043 | Valid Loss: 277.6435241699219\n",
      "Epoch: 53 | Train Loss: 322.71615538305167 | Valid Loss: 277.6435241699219\n",
      "Epoch: 54 | Train Loss: 285.2226381885762 | Valid Loss: 277.6435241699219\n",
      "Epoch: 55 | Train Loss: 277.5483820389728 | Valid Loss: 277.6435241699219\n",
      "Epoch: 56 | Train Loss: 282.9349801199777 | Valid Loss: 277.6435241699219\n",
      "Epoch: 57 | Train Loss: 366.76579814054526 | Valid Loss: 277.6435241699219\n",
      "Epoch: 58 | Train Loss: 289.95950862339566 | Valid Loss: 277.6435241699219\n",
      "Epoch: 59 | Train Loss: 285.09829400510205 | Valid Loss: 277.6435241699219\n",
      "Epoch: 60 | Train Loss: 387.15134040676816 | Valid Loss: 277.6435241699219\n",
      "Epoch: 61 | Train Loss: 344.8323333117427 | Valid Loss: 277.6435241699219\n",
      "Epoch: 62 | Train Loss: 305.136511977838 | Valid Loss: 277.6435241699219\n",
      "Epoch: 63 | Train Loss: 291.0151915258291 | Valid Loss: 277.6435241699219\n",
      "Epoch: 64 | Train Loss: 366.907884247449 | Valid Loss: 277.6435241699219\n",
      "Epoch: 65 | Train Loss: 387.37972960180167 | Valid Loss: 277.6435241699219\n",
      "Epoch: 66 | Train Loss: 393.46618122957193 | Valid Loss: 277.6435241699219\n",
      "Epoch: 67 | Train Loss: 297.95844253228637 | Valid Loss: 277.6435241699219\n",
      "Epoch: 68 | Train Loss: 289.23118560168206 | Valid Loss: 277.6435241699219\n",
      "Epoch: 69 | Train Loss: 303.295368428133 | Valid Loss: 277.6435241699219\n",
      "Epoch: 70 | Train Loss: 370.5446802256059 | Valid Loss: 267.6595764160156\n",
      "Epoch: 71 | Train Loss: 318.2922930036272 | Valid Loss: 267.6595764160156\n",
      "Epoch: 72 | Train Loss: 284.11743880291374 | Valid Loss: 267.6595764160156\n",
      "Epoch: 73 | Train Loss: 255.67738887241907 | Valid Loss: 267.6595764160156\n",
      "Epoch: 74 | Train Loss: 270.8396442569032 | Valid Loss: 267.6595764160156\n",
      "Epoch: 75 | Train Loss: 248.11394827706474 | Valid Loss: 267.6595764160156\n",
      "Epoch: 76 | Train Loss: 302.0379741435148 | Valid Loss: 267.6595764160156\n",
      "Epoch: 77 | Train Loss: 339.1699969233299 | Valid Loss: 267.6595764160156\n",
      "Epoch: 78 | Train Loss: 294.84714118801816 | Valid Loss: 267.6595764160156\n",
      "Epoch: 79 | Train Loss: 387.090989716199 | Valid Loss: 267.6595764160156\n",
      "Epoch: 80 | Train Loss: 344.0594569614955 | Valid Loss: 267.6595764160156\n",
      "Epoch: 81 | Train Loss: 291.40451258056015 | Valid Loss: 267.6595764160156\n",
      "Epoch: 82 | Train Loss: 242.94692619479432 | Valid Loss: 267.6595764160156\n",
      "Epoch: 83 | Train Loss: 316.1305853396046 | Valid Loss: 267.6595764160156\n",
      "Epoch: 84 | Train Loss: 278.4092327040069 | Valid Loss: 267.6595764160156\n",
      "Epoch: 85 | Train Loss: 279.47438158307756 | Valid Loss: 267.6595764160156\n",
      "Epoch: 86 | Train Loss: 255.09499561543367 | Valid Loss: 267.6595764160156\n",
      "Epoch: 87 | Train Loss: 266.12111056580835 | Valid Loss: 267.6595764160156\n",
      "Epoch: 88 | Train Loss: 277.1225160871233 | Valid Loss: 267.6595764160156\n",
      "Epoch: 89 | Train Loss: 260.13817861128825 | Valid Loss: 267.6595764160156\n",
      "Epoch: 90 | Train Loss: 254.2926068987165 | Valid Loss: 267.6595764160156\n",
      "Epoch: 91 | Train Loss: 288.6881066147162 | Valid Loss: 245.20648193359375\n",
      "Epoch: 92 | Train Loss: 238.50795823700574 | Valid Loss: 245.20648193359375\n",
      "Epoch: 93 | Train Loss: 228.66775045589526 | Valid Loss: 245.20648193359375\n",
      "Epoch: 94 | Train Loss: 220.07986201072225 | Valid Loss: 245.20648193359375\n",
      "Epoch: 95 | Train Loss: 219.5265110560826 | Valid Loss: 245.20648193359375\n",
      "Epoch: 96 | Train Loss: 227.9528045654297 | Valid Loss: 245.20648193359375\n",
      "Epoch: 97 | Train Loss: 282.2487036257374 | Valid Loss: 245.20648193359375\n",
      "Epoch: 98 | Train Loss: 210.32729728854432 | Valid Loss: 245.20648193359375\n",
      "Epoch: 99 | Train Loss: 221.34437187350525 | Valid Loss: 245.20648193359375\n",
      "Epoch: 100 | Train Loss: 209.71528999172912 | Valid Loss: 225.18399047851562\n",
      "Epoch: 101 | Train Loss: 208.6652726153938 | Valid Loss: 225.18399047851562\n",
      "Epoch: 102 | Train Loss: 233.68317004612513 | Valid Loss: 225.18399047851562\n",
      "Epoch: 103 | Train Loss: 213.99595291760502 | Valid Loss: 225.18399047851562\n",
      "Epoch: 104 | Train Loss: 213.9903078663106 | Valid Loss: 225.18399047851562\n",
      "Epoch: 105 | Train Loss: 201.29559699856506 | Valid Loss: 225.18399047851562\n",
      "Epoch: 106 | Train Loss: 294.7989827370157 | Valid Loss: 225.18399047851562\n",
      "Epoch: 107 | Train Loss: 231.11661140286193 | Valid Loss: 225.18399047851562\n",
      "Epoch: 108 | Train Loss: 218.6974604859644 | Valid Loss: 225.18399047851562\n",
      "Epoch: 109 | Train Loss: 222.60065008669483 | Valid Loss: 225.18399047851562\n",
      "Epoch: 110 | Train Loss: 205.46032621422592 | Valid Loss: 225.18399047851562\n",
      "Epoch: 111 | Train Loss: 325.59316923180404 | Valid Loss: 225.18399047851562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 112 | Train Loss: 302.56445748465404 | Valid Loss: 225.18399047851562\n",
      "Epoch: 113 | Train Loss: 247.79267167071907 | Valid Loss: 225.18399047851562\n",
      "Epoch: 114 | Train Loss: 338.780262538365 | Valid Loss: 225.18399047851562\n",
      "Epoch: 115 | Train Loss: 246.28164735132333 | Valid Loss: 225.18399047851562\n",
      "Epoch: 116 | Train Loss: 228.25972202845983 | Valid Loss: 219.59442138671875\n",
      "Epoch: 117 | Train Loss: 246.83865776840523 | Valid Loss: 219.59442138671875\n",
      "Epoch: 118 | Train Loss: 263.43966861647004 | Valid Loss: 219.59442138671875\n",
      "Epoch: 119 | Train Loss: 252.1708423848055 | Valid Loss: 219.59442138671875\n",
      "Epoch: 120 | Train Loss: 229.46193944191447 | Valid Loss: 219.59442138671875\n",
      "Epoch: 121 | Train Loss: 248.17331329657108 | Valid Loss: 219.59442138671875\n",
      "Epoch: 122 | Train Loss: 185.7667918302575 | Valid Loss: 219.59442138671875\n",
      "Epoch: 123 | Train Loss: 225.8721039441167 | Valid Loss: 219.59442138671875\n",
      "Epoch: 124 | Train Loss: 243.7763852489238 | Valid Loss: 219.59442138671875\n",
      "Epoch: 125 | Train Loss: 245.79571797896403 | Valid Loss: 219.59442138671875\n",
      "Epoch: 126 | Train Loss: 211.22874123709542 | Valid Loss: 219.59442138671875\n",
      "Epoch: 127 | Train Loss: 189.59907749720983 | Valid Loss: 219.59442138671875\n",
      "Epoch: 128 | Train Loss: 218.13675860969389 | Valid Loss: 219.59442138671875\n",
      "Epoch: 129 | Train Loss: 234.44907363580197 | Valid Loss: 219.59442138671875\n",
      "Epoch: 130 | Train Loss: 288.54251596878987 | Valid Loss: 219.59442138671875\n",
      "Epoch: 131 | Train Loss: 198.2778102719054 | Valid Loss: 219.59442138671875\n",
      "Epoch: 132 | Train Loss: 270.39718503368147 | Valid Loss: 219.59442138671875\n",
      "Epoch: 133 | Train Loss: 174.89728032326212 | Valid Loss: 219.59442138671875\n",
      "Epoch: 134 | Train Loss: 190.4991140560228 | Valid Loss: 219.59442138671875\n",
      "Epoch: 135 | Train Loss: 172.51128247319434 | Valid Loss: 218.86830139160156\n",
      "Epoch: 136 | Train Loss: 186.48512143504863 | Valid Loss: 218.86830139160156\n",
      "Epoch: 137 | Train Loss: 174.24581161810428 | Valid Loss: 218.86830139160156\n",
      "Epoch: 138 | Train Loss: 182.60935880699935 | Valid Loss: 218.86830139160156\n",
      "Epoch: 139 | Train Loss: 185.2538081577846 | Valid Loss: 218.86830139160156\n",
      "Epoch: 140 | Train Loss: 219.48164336535396 | Valid Loss: 218.86830139160156\n",
      "Epoch: 141 | Train Loss: 192.18976888851245 | Valid Loss: 218.86830139160156\n",
      "Epoch: 142 | Train Loss: 188.66744092045997 | Valid Loss: 218.86830139160156\n",
      "Epoch: 143 | Train Loss: 171.84272843964246 | Valid Loss: 218.86830139160156\n",
      "Epoch: 144 | Train Loss: 177.12071819694674 | Valid Loss: 197.51202392578125\n",
      "Epoch: 145 | Train Loss: 161.868093685228 | Valid Loss: 197.51202392578125\n",
      "Epoch: 146 | Train Loss: 172.8850608358578 | Valid Loss: 197.51202392578125\n",
      "Epoch: 147 | Train Loss: 269.9581278586874 | Valid Loss: 197.51202392578125\n",
      "Epoch: 148 | Train Loss: 231.17994409677934 | Valid Loss: 197.51202392578125\n",
      "Epoch: 149 | Train Loss: 167.84581118213887 | Valid Loss: 197.51202392578125\n",
      "Epoch: 150 | Train Loss: 173.87675662916533 | Valid Loss: 197.51202392578125\n",
      "Epoch: 151 | Train Loss: 169.06484938640983 | Valid Loss: 197.51202392578125\n",
      "Epoch: 152 | Train Loss: 241.92081163367448 | Valid Loss: 197.51202392578125\n",
      "Epoch: 153 | Train Loss: 194.37459268375318 | Valid Loss: 194.85488891601562\n",
      "Epoch: 154 | Train Loss: 158.8254544005102 | Valid Loss: 194.85488891601562\n",
      "Epoch: 155 | Train Loss: 147.92360827387597 | Valid Loss: 194.85488891601562\n",
      "Epoch: 156 | Train Loss: 171.70353356186226 | Valid Loss: 194.85488891601562\n",
      "Epoch: 157 | Train Loss: 175.5025964853715 | Valid Loss: 194.85488891601562\n",
      "Epoch: 158 | Train Loss: 146.46981780383052 | Valid Loss: 191.46412658691406\n",
      "Epoch: 159 | Train Loss: 143.73437764693278 | Valid Loss: 191.46412658691406\n",
      "Epoch: 160 | Train Loss: 146.39058202626754 | Valid Loss: 191.46412658691406\n",
      "Epoch: 161 | Train Loss: 129.51487794214364 | Valid Loss: 191.46412658691406\n",
      "Epoch: 162 | Train Loss: 154.23718067091338 | Valid Loss: 191.46412658691406\n",
      "Epoch: 163 | Train Loss: 150.28981236049108 | Valid Loss: 191.46412658691406\n",
      "Epoch: 164 | Train Loss: 188.01096593117228 | Valid Loss: 188.2588348388672\n",
      "Epoch: 165 | Train Loss: 187.7456615214445 | Valid Loss: 188.2588348388672\n",
      "Epoch: 166 | Train Loss: 195.4741263876156 | Valid Loss: 188.2588348388672\n",
      "Epoch: 167 | Train Loss: 207.2942297020737 | Valid Loss: 188.2588348388672\n",
      "Epoch: 168 | Train Loss: 167.58966126733895 | Valid Loss: 188.2588348388672\n",
      "Epoch: 169 | Train Loss: 176.027898048868 | Valid Loss: 188.2588348388672\n",
      "Epoch: 170 | Train Loss: 168.56955329739318 | Valid Loss: 188.2588348388672\n",
      "Epoch: 171 | Train Loss: 178.34200191497803 | Valid Loss: 188.2588348388672\n",
      "Epoch: 172 | Train Loss: 220.72632334183675 | Valid Loss: 182.54869079589844\n",
      "Epoch: 173 | Train Loss: 257.083487374442 | Valid Loss: 182.54869079589844\n",
      "Epoch: 174 | Train Loss: 194.4823770328444 | Valid Loss: 182.54869079589844\n",
      "Epoch: 175 | Train Loss: 181.45991920938297 | Valid Loss: 182.54869079589844\n",
      "Epoch: 176 | Train Loss: 152.14623182647082 | Valid Loss: 182.54869079589844\n",
      "Epoch: 177 | Train Loss: 195.22320930325256 | Valid Loss: 182.54869079589844\n",
      "Epoch: 178 | Train Loss: 294.35370869539224 | Valid Loss: 182.54869079589844\n",
      "Epoch: 179 | Train Loss: 274.3086591448103 | Valid Loss: 182.54869079589844\n",
      "Epoch: 180 | Train Loss: 301.53676792066926 | Valid Loss: 182.54869079589844\n",
      "Epoch: 181 | Train Loss: 223.7448079634686 | Valid Loss: 182.54869079589844\n",
      "Epoch: 182 | Train Loss: 195.2721457967953 | Valid Loss: 182.54869079589844\n",
      "Epoch: 183 | Train Loss: 176.5775205651108 | Valid Loss: 182.54869079589844\n",
      "Epoch: 184 | Train Loss: 175.7100830078125 | Valid Loss: 182.54869079589844\n",
      "Epoch: 185 | Train Loss: 147.8838424098735 | Valid Loss: 182.54869079589844\n",
      "Epoch: 186 | Train Loss: 166.19882155437858 | Valid Loss: 182.54869079589844\n",
      "Epoch: 187 | Train Loss: 194.71087179378588 | Valid Loss: 182.54869079589844\n",
      "Epoch: 188 | Train Loss: 130.35266105496154 | Valid Loss: 182.54869079589844\n",
      "Epoch: 189 | Train Loss: 130.86746215820312 | Valid Loss: 182.54869079589844\n",
      "Epoch: 190 | Train Loss: 191.22568901217713 | Valid Loss: 177.7175750732422\n",
      "Epoch: 191 | Train Loss: 161.6269419144611 | Valid Loss: 177.7175750732422\n",
      "Epoch: 192 | Train Loss: 173.92731148856026 | Valid Loss: 177.7175750732422\n",
      "Epoch: 193 | Train Loss: 143.5522271759656 | Valid Loss: 177.7175750732422\n",
      "Epoch: 194 | Train Loss: 147.6805866786412 | Valid Loss: 177.7175750732422\n",
      "Epoch: 195 | Train Loss: 140.35635858652543 | Valid Loss: 177.7175750732422\n",
      "Epoch: 196 | Train Loss: 136.82810724998006 | Valid Loss: 177.7175750732422\n",
      "Epoch: 197 | Train Loss: 159.24272280323262 | Valid Loss: 177.7175750732422\n",
      "Epoch: 198 | Train Loss: 125.55351685504525 | Valid Loss: 172.68075561523438\n",
      "Epoch: 199 | Train Loss: 127.129099787498 | Valid Loss: 172.68075561523438\n",
      "Epoch: 200 | Train Loss: 134.26910883066606 | Valid Loss: 172.68075561523438\n",
      "Epoch: 201 | Train Loss: 135.95699773515975 | Valid Loss: 172.68075561523438\n",
      "Epoch: 202 | Train Loss: 113.17997780624701 | Valid Loss: 172.68075561523438\n",
      "Epoch: 203 | Train Loss: 123.02040240229393 | Valid Loss: 172.68075561523438\n",
      "Epoch: 204 | Train Loss: 123.22411642269212 | Valid Loss: 172.68075561523438\n",
      "Epoch: 205 | Train Loss: 147.509239975287 | Valid Loss: 172.68075561523438\n",
      "Epoch: 206 | Train Loss: 192.59700821857064 | Valid Loss: 172.68075561523438\n",
      "Epoch: 207 | Train Loss: 168.8883729272959 | Valid Loss: 172.68075561523438\n",
      "Epoch: 208 | Train Loss: 188.51761362503987 | Valid Loss: 172.68075561523438\n",
      "Epoch: 209 | Train Loss: 176.5924584524972 | Valid Loss: 172.68075561523438\n",
      "Epoch: 210 | Train Loss: 175.2610204268475 | Valid Loss: 172.68075561523438\n",
      "Epoch: 211 | Train Loss: 160.82906014578683 | Valid Loss: 172.68075561523438\n",
      "Epoch: 212 | Train Loss: 153.2851098508251 | Valid Loss: 172.68075561523438\n",
      "Epoch: 213 | Train Loss: 175.40839915372888 | Valid Loss: 172.68075561523438\n",
      "Epoch: 214 | Train Loss: 175.81055399836328 | Valid Loss: 172.68075561523438\n",
      "Epoch: 215 | Train Loss: 183.0003677290313 | Valid Loss: 172.68075561523438\n",
      "Epoch: 216 | Train Loss: 164.3163565810846 | Valid Loss: 172.68075561523438\n",
      "Epoch: 217 | Train Loss: 188.81729624222737 | Valid Loss: 172.68075561523438\n",
      "Epoch: 218 | Train Loss: 152.104426169882 | Valid Loss: 172.68075561523438\n",
      "Epoch: 219 | Train Loss: 159.5468824736926 | Valid Loss: 172.68075561523438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 220 | Train Loss: 167.36201336919044 | Valid Loss: 172.68075561523438\n",
      "Epoch: 221 | Train Loss: 171.3050185223015 | Valid Loss: 172.68075561523438\n",
      "Epoch: 222 | Train Loss: 137.2573024204799 | Valid Loss: 172.68075561523438\n",
      "Epoch: 223 | Train Loss: 162.60741541336995 | Valid Loss: 172.68075561523438\n",
      "Epoch: 224 | Train Loss: 143.56324402166874 | Valid Loss: 172.68075561523438\n",
      "Epoch: 225 | Train Loss: 142.20476874526665 | Valid Loss: 172.68075561523438\n",
      "Epoch: 226 | Train Loss: 144.14681197185905 | Valid Loss: 172.68075561523438\n",
      "Epoch: 227 | Train Loss: 158.22171830157845 | Valid Loss: 172.68075561523438\n",
      "Epoch: 228 | Train Loss: 131.87291608537947 | Valid Loss: 172.68075561523438\n",
      "Epoch: 229 | Train Loss: 314.16031319754467 | Valid Loss: 172.68075561523438\n",
      "Epoch: 230 | Train Loss: 280.93201306401465 | Valid Loss: 172.68075561523438\n",
      "Epoch: 231 | Train Loss: 284.55378326104614 | Valid Loss: 172.68075561523438\n",
      "Epoch: 232 | Train Loss: 193.269005600287 | Valid Loss: 172.68075561523438\n",
      "Epoch: 233 | Train Loss: 150.895751953125 | Valid Loss: 172.68075561523438\n",
      "Epoch: 234 | Train Loss: 149.85033922779317 | Valid Loss: 172.68075561523438\n",
      "Epoch: 235 | Train Loss: 146.75028524593432 | Valid Loss: 172.68075561523438\n",
      "Epoch: 236 | Train Loss: 141.05326500717476 | Valid Loss: 172.68075561523438\n",
      "Epoch: 237 | Train Loss: 133.39932531240035 | Valid Loss: 172.68075561523438\n",
      "Epoch: 238 | Train Loss: 146.65954340720663 | Valid Loss: 172.68075561523438\n",
      "Epoch: 239 | Train Loss: 193.2853001185826 | Valid Loss: 172.68075561523438\n",
      "Epoch: 240 | Train Loss: 196.85298623844068 | Valid Loss: 172.68075561523438\n",
      "Epoch: 241 | Train Loss: 197.72887669777384 | Valid Loss: 172.68075561523438\n",
      "Epoch: 242 | Train Loss: 224.9493476711974 | Valid Loss: 172.68075561523438\n",
      "Epoch: 243 | Train Loss: 222.66225822604432 | Valid Loss: 172.68075561523438\n",
      "Epoch: 244 | Train Loss: 178.95939137984294 | Valid Loss: 172.68075561523438\n",
      "Epoch: 245 | Train Loss: 150.731830207669 | Valid Loss: 172.68075561523438\n",
      "Epoch: 246 | Train Loss: 135.4864350143744 | Valid Loss: 172.68075561523438\n",
      "Epoch: 247 | Train Loss: 125.06689577686544 | Valid Loss: 172.68075561523438\n",
      "Epoch: 248 | Train Loss: 196.16824153977998 | Valid Loss: 172.68075561523438\n",
      "Epoch: 249 | Train Loss: 184.46219814066984 | Valid Loss: 172.68075561523438\n",
      "Epoch: 250 | Train Loss: 196.36753845214844 | Valid Loss: 172.68075561523438\n",
      "Epoch: 251 | Train Loss: 131.47645942532287 | Valid Loss: 172.68075561523438\n",
      "Epoch: 252 | Train Loss: 125.13855572136082 | Valid Loss: 172.68075561523438\n",
      "Epoch: 253 | Train Loss: 124.47392054966518 | Valid Loss: 172.68075561523438\n",
      "Epoch: 254 | Train Loss: 136.8445096697126 | Valid Loss: 172.68075561523438\n",
      "Epoch: 255 | Train Loss: 137.79310639050541 | Valid Loss: 172.68075561523438\n",
      "Epoch: 256 | Train Loss: 140.21692657470703 | Valid Loss: 172.68075561523438\n",
      "Epoch: 257 | Train Loss: 105.16891479492188 | Valid Loss: 172.68075561523438\n",
      "Epoch: 258 | Train Loss: 134.72085368876554 | Valid Loss: 172.68075561523438\n",
      "Epoch: 259 | Train Loss: 135.24096555125956 | Valid Loss: 172.68075561523438\n",
      "Epoch: 260 | Train Loss: 118.45348996532206 | Valid Loss: 172.68075561523438\n",
      "Epoch: 261 | Train Loss: 149.74386565539302 | Valid Loss: 172.68075561523438\n",
      "Epoch: 262 | Train Loss: 123.47082628522601 | Valid Loss: 172.68075561523438\n"
     ]
    }
   ],
   "source": [
    "go = GraphOperator(config=training_config)\n",
    "go.train(X_train, y_train, model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-malawi",
   "metadata": {},
   "source": [
    "Let's get predictions, then calculate prediction errors for the training and testing subsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extended-charlotte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set: R2 = 0.18519368963827088, MAE = 9.106616592407228\n",
      "Train Set: R2 = 0.6523856649656592, MAE = 6.182180023193361\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = go.use(X_train)\n",
    "y_test_pred = go.use(X_test)\n",
    "\n",
    "mae_test = median_absolute_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "mae_train = median_absolute_error(y_train, y_train_pred)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "print('Test Set: R2 = {}, MAE = {}'.format(r2_test, mae_test))\n",
    "print('Train Set: R2 = {}, MAE = {}'.format(r2_train, mae_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-stomach",
   "metadata": {},
   "source": [
    "And let's plot our results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "second-rocket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Predicted MON vs. Experimental MON')\n",
    "plt.xlabel('Experimental Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "plt.scatter(y_train, y_train_pred, color='blue', label='Train')\n",
    "plt.scatter(y_test, y_test_pred, color='red', label='Test')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-array",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
